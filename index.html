
<!DOCTYPE html>
<!-- saved from url=(0040)http://artemsheludko.pw/flexible-jekyll/ -->
<html lang="en">

<head>
	
<!-- <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?1833684faf5f254c1bb31386c5780c57";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script> -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');

</script>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Haoyue Liu-刘昊岳</title>
<link rel="shortcut icon" href="img/hyliu.jpg"/>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Haoyue Liu, Huazhong University of Science and Technology"> 
<meta name="description" content="Haoyue Liu's home page">
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<!-- <link rel="stylesheet" href="./css/jemdoc.css"> -->
<link rel="stylesheet" href="./css/jemdoc.css" type="text/css">
<title>Haoyue Liu, Huazhong University of Science and Technology</title>
</head>

<!-- <body>
 <div id="layout-content" style="margin-top:25px">
 <a href="https://Liu-haoyue.github.io/" class="github-corner"><svg width="80" height="80" viewBox="0 0 250 250"
 style="fill:#0000FF; color:#fff; position: absolute; top: 0; border: 0; right: 0;"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z">
 </path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,
 87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
 <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 
 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,
 77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,
 116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>
 <style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,
 60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px)
 {.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style> -->
	
	
	
	
<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1>Haoyue Liu &nbsp 刘昊岳 </h1><h1>
				</h1></div>

				<h3> Ph.D. Student </h3>
				<p>
					1037 Luoyu Road,<br>
					Huazhong University of Science and Technology (HUST), <br>
					Wuhan, China, 430074 <br>
					<br>
					Email:  liuhy@hust.edu.cn
					       
				</p>
				<p>     
					
					<!-- <a href="paper/CV.pdf"><img src="img/cv_p.jpg"  height="40px" style="margin-bottom:-3px"></a> -->
					<a href="https://github.com/Liu-haoyue"><img src="img/github.jpg" height="40px" style="margin-bottom:-3px"></a>
					<a href="https://scholar.google.com/citations?hl=zh-CN&user=DadbHdAAAAAJ"><img src="img/google-logo.png"  height="40px" style="margin-bottom:-3px"></a>
					<a href="https://www.linkedin.com/in/haoyue-liu-3b111226a/"><img src="img/linkedin.jpg"  height="40px" style="margin-bottom:-3px"></a>
<!-- 					<a href="img/weichat.pdf"><img src="img/weichat.jpg"  height="40px" style="margin-bottom:-3px"></a> -->
				</p>
			</td>
			<td>
				<a href="https://Liu-haoyue.github.io/"><img src="img/hyliu.jpg" alt="Haoyue Liu" border="0" height="300"></a><br>
			</td>
		</tr><tr>
	</tr>
	</tbody>
</table>
	
    <h2>Biography</h2>
    <div id="news-content" >
	  <span>
		I am currently a Ph.D. student in Huazhong University of Science and Technology (HUST).
		Before that, I got the M.S. degree and the B.E. degree from China University of Mining and Technology (CUMT) in 2013 and 2016 respectively. I worked as a image algorithm researcher for the AI Lab at TK.cn CO.,LTD for several years.
		I am now looking for a postdoctoral fellow position, if you have an excellent project or an open position that can match my research philosophy, please <span style="color:Red"><strong>email me!</strong></span> </span> <br> <br> 

	</div>

	<h2>Interests</h2>
    <div id="news-content" >
	  <span>
		Event camera, Nighttime imaging, HDR imaging, Multimodal Learning.</span> <br> <br> 
    </div>
	 

      <h2>News</h2>
      <div style="height: 250; overflow: auto;">
      <ul>
      <li><span style="color:Red">2024.02</span>, Our work for event-based nighttime HDR imaging has been accepted by <strong><i>CVPR'24</i></strong>.</li>
	  <li><span style="color:Red">2024.02</span>, Our work for event-based nighttime optical flow estimation has been accepted by <strong><i>ICLR'24</i></strong> (<span style="color:Red"><strong>Spotlight</strong></span>).</li>
      <li><span style="color:Red">2023.06</span>, We have won 1st place in the track 'Atmospheric Turbulence Mitigation' in the <strong><i>CVPR'23 UG2+</i></strong> Challenge.</li> 
      </ul>
    </div>
     
     <h2>Researches</h2>
    <div id="news-content" >
	   <span>
		In dynamic scenes with extreme lighting conditions, the visual signals captured by conventional cameras degrade, posing challenges for scene imaging and perception tasks. 
		Event cameras are a new type of sensor, which independently activates each pixel based on changes in brightness. This sensor offers several significant advantages, 
		including a high dynamic range (120dB) and high temporal resolution (1μs) , providing a novel approach for imaging and perception in extreme lighting environments. 
		Dr. Liu and his team have built a multimodal data acquisition platform and designed efficient machine learning algorithms to train state-of-the-art deep models, 
		achieving the goal of imaging and perception in dynamic scenes with complex lighting.
		<br> <br> 

		1. Constructing a paired real low-light event dataset (RLED). Specifically, Dr. Liu design a <strong>co-axial imaging system</strong>comprising an event camera with a neutral density(ND) filter and a conventional camera, which
		allows for the simultaneous acquisition of low-light events	and high-quality images. RLED provides 64,200 images with corresponding events, capturing events illuminance levels	ranging from 0.5 lux to 1000 lux.
		The research outputs have been published in <strong><i><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Liu_Seeing_Motion_at_Nighttime_with_an_Event_Camera_CVPR_2024_paper.pdf">CVPR 2024</a></i></strong>.
        <br> <br> 

		<!-- <span style="display: block; margin-left: auto; margin-right: auto;"> -->
		<div style="display: flex; justify-content: center;">
		<img src="img/research_1_1.jpg"  height="300px" width="300px" style="margin-left: auto; margin-right: 0px;">
		<img src="img/research_1_2.gif"  height="300px" width="620px" style="margin-left: 3px; margin-right: auto;"> </div>
		<br>
		
		
		2. Constructing a <strong>multimodality perception system</strong> and a large-scale multimodal dataset. 
		Consisdering the scarcity of all-day and all weather motion datasets,
		Dr. Liu and his team constructs a RGB-Event-LiDAR-IMU multimodality perception system with spatiotemporal alignment, 
		and builds a large-scale multimodal dataset under various time (<i>e.g.</i>, daytime and nighttime) and various weather (<i>e.g.</i>, rain, fog and snow).
		The research outputs are comming soon.
        <br> <br> 

		<!-- <span style="display: block; margin-left: auto; margin-right: auto;"> -->
		<div style="display: flex; justify-content: center;">
		<img src="img/research_2_1.png"  height="300px" width="340px" style="margin-left: auto; margin-right: 0px;">
		<img src="img/research_2_2.gif"  height="300px" width="577px" style="margin-left: 3px; margin-right: auto;"> </div>
		<br>

		      
	</span>
	<br>
    </div>
	  
     
<tr><tr><tr><tr>
<div style="margin-top: 10px"></div>
    <h2>Publications <a href="https://scholar.google.com/citations?hl=zh-CN&user=DadbHdAAAAAJ">(Google Scholar)</a> </h2>
      
<table id="tbPublications" width="100%">
<tbody>
<!-- <span>(*:Co-First Author; #:Corresponding Author) </span> -->
<!-- <h3 style="color: red">Conference Papers </h3>	 -->
	<tr>
		<td width="206">
		<img src="publication/CVPR2024-NER-Net.png" width="185px" height = "100" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="https://arxiv.org/pdf/2404.11884.pdf" target="_blank"> Seeing Motion at Nighttime with an Event Camera.</a>
		<p ><strong>Haoyue Liu</strong>, Shihan Peng, Lin Zhu, Yi Chang, Hanyu, Luxin Yan.</p>
	<p style="margin-top: -11px"><i>IEEE Conference on Computer Vision and Pattern Recognition (<strong> CVPR </strong>), 2024.</i></p>
		<p>
			[<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Liu_Seeing_Motion_at_Nighttime_with_an_Event_Camera_CVPR_2024_paper.pdf">PDF</a>]
			[<a href="https://openaccess.thecvf.com/content/CVPR2024/supplemental/Liu_Seeing_Motion_at_CVPR_2024_supplemental.zip">supp</a>]
			[<a href="https://arxiv.org/pdf/2404.11884.pdf">arXiv</a>]
			[<a href="https://github.com/Liu-haoyue/NER-Net">Code</a>]
		</p>
		</td>
	</tr>
	<tr></tr>
	<tr></tr>

	<tr>
	<td width="206">
		<img src="publication/ICLR2024-ABDA.png" width="185px" height = "100" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="https://arxiv.org/pdf/2403.07432.pdf" target="_blank"> Exploring the Common Appearance-Boundary Adaptation for Nighttime Optical Flow.</a>
		 <p >Hanyu Zhou, Yi Chang, <strong>Haoyue Liu</strong>, Wending Yan, Yuxing Duan, Zhiwei Shi, Luxin Yan.</p>
       <p style="margin-top: -11px"><i>International Conference on Learning Representations (<strong> ICLR </strong>), <strong><span style="color:Red">Spotlight</span></strong>, 2024.</i></p>
		<p>[<a href="https://openreview.net/pdf?id=776lhoaulC">PDF</a>] [<a href="https://arxiv.org/pdf/2401.17642.pdf">arXiv</a>]
		</p>
		</td>
	</tr>
	<tr></tr>
	<tr></tr>
	
<table id="tbPublications" width="100%">
<tbody>
	<h3 style="color: red">Preprint Papers </h3>	
	<tr>

	<td width="206">
		<img src="publication/TPAMI2024.jpg" width="185px" height = "100" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="https://Liu-haoyue.github.io/" target="_blank"> Seeing Motion at Nighttime under Extreme lighting with an Event Camera.</a>
		 <p ><strong>Haoyue Liu</strong>, Jinghan Xu, Yuxing Duan, Hanyu Zhou, Yi Chang, Luxin Yan, Yonghong Tian.</p>
       <p style="margin-top: -11px"><i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong> TPAMI </strong>), Under review, 2024.</i></p>
		</td>
	</tr>
	<tr></tr>
	<tr></tr>




</tbody>
</table>
	  
	  
    <h2><strong>Awards</strong></h2>
	<br>
   <div id="news-content">
	<li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2021.09-2024.06</span>, <strong>First-class Scholarship for Doctoral Students</strong>.</li>
	<li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2023.12</span>, <strong>Active Participants Award in Extracurricular Activities</strong>.</li>
	<li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2023.06</span>, <strong> 1st place in the track 'Atmospheric Turbulence Mitigation' in the CVPR'23 UG2+ Challenge</strong>.</li>
	<li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2022.12</span>, <strong>Excellent Postgraduate Cadre Award</strong>.</li>
    </div>  
   
	 
     <!-- <h2><strong>Academic Services</strong></h2>
   <div>   
	<strong>Journal Reviewers:</strong> 
	TIP, TCSVT, MTAP.<br>
	
	<strong>Conference Reviewers:</strong> 
	CVPR'23-24, AAAI'23-24, ECCV'24, ICRA'24.
    </div> -->
	
	   

     <div id="footer">
	<div id="footer-text"></div>
    </div>
    <div id = "logo" style="margin-top: 10px; text-align:center">
	    <div align="center" style="margin:auto;padding-top:10px">
            <div align="center">
                <!-- <script type='text/javascript' id='mapmyvisitors' src='https://mapmyvisitors.com/map.js?cl=ffffff&w=400&t=tt&d=RvNs3EgaHTaj7HSSlDqnISVThDMgV3AdypyqNFyt5XA'></script> -->
				<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=400&t=tt&d=_g7EuEi2n2P13A9qVnjZlOQ8ZAWxW-5o8CWk07N90ms'></script>
			</div>
           <br>
        &copy; Haoyue Liu | <span style="color:Red">Last updated: June., 2024</span>
            </div>
     </div>     
	
    
  </div>

</body></html>
